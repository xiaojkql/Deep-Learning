{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 MINIST数据集简介，该数据集共有四个文件，即[(训练数据，训练数据标签):60000，(测试数据，测试数据标签):10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Extracting MINIST_DATA\\train-images-idx3-ubyte.gz\n",
      "Extracting MINIST_DATA\\train-labels-idx1-ubyte.gz\n",
      "Extracting MINIST_DATA\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MINIST_DATA\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# some simple sets up\n",
    "\n",
    "import os\n",
    "import scipy.misc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# magic setting\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# 忽略警告\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 载入数据\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "minist = input_data.read_data_sets(\"MINIST_DATA\",one_hot=True) # one_hot is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traininig data shape:\n",
      "(55000, 784)\n",
      "(55000, 10)\n",
      "\n",
      "validation data shape:\n",
      "(5000, 784)\n",
      "(5000, 10)\n",
      "\n",
      "test data shape:\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# train imges\n",
    "print(\"traininig data shape:\")\n",
    "print(minist.train.images.shape)\n",
    "print(minist.train.labels.shape)\n",
    "print()\n",
    "\n",
    "# validation images\n",
    "print(\"validation data shape:\")\n",
    "print(minist.validation.images.shape)\n",
    "print(minist.validation.labels.shape)\n",
    "print()\n",
    "\n",
    "# test images\n",
    "print(\"test data shape:\")\n",
    "print(minist.test.images.shape)\n",
    "print(minist.test.labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原来的图像数据为一维向量，方便计算，方便保存，下面将此一维向量转换为一维矩阵，即还原为图像\n",
    "\n",
    "知识点：\n",
    "- python 的文件操作\n",
    "- scipy.misc转换为图像的功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'arr' does not have a suitable array shape for any mode.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-24ef03ddd4b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_raw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"minist_train_image_%d\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoimage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Software\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\numpy\\lib\\utils.py\u001b[0m in \u001b[0;36mnewfunc\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[1;34m\"\"\"`arrayrange` is deprecated, use `arange` instead!\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mnewfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_set_function_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\scipy\\misc\\pilutil.py\u001b[0m in \u001b[0;36mtoimage\u001b[1;34m(arr, high, low, cmin, cmax, pal, mode, channel_axis)\u001b[0m\n\u001b[0;32m    325\u001b[0m                                 ((3 in shape) or (4 in shape)))\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m         raise ValueError(\"'arr' does not have a suitable array shape for \"\n\u001b[0m\u001b[0;32m    328\u001b[0m                          \"any mode.\")\n\u001b[0;32m    329\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'arr' does not have a suitable array shape for any mode."
     ]
    }
   ],
   "source": [
    "# 在代码中打开或创建一个文件夹的方法\n",
    "save_dir = 'MINIST_DATA/raw/'\n",
    "if os.path.exists(save_dir) is False:\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# 保存前20张图片\n",
    "for i in range(20):\n",
    "    image_array = minist.train.images[i,:] # 会降维\n",
    "    image_raw = np.reshape(image_array,(28,28))\n",
    "    filename = save_dir+\"minist_train_image_%d\"%i\n",
    "    scipy.misc.toimage(image_array,cmin=0.0,cmax=1.0).save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 图像标签的独热表示  \n",
    "\n",
    "啥叫独热表示：one-hot representation,一位有效编码，用N维向量来表示N个类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 打印前20张image的独热表示，找到他们的类别\n",
    "for i in range(20):\n",
    "    print(minist.train.labels[i,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 利用TensorFlow 识别MNIST\n",
    "\n",
    "手写识别程序，模型为softmax模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Softmax回归\n",
    "\n",
    "1. softmax回归的原理\n",
    "\n",
    "线性的多分类模型，由logistic回归模型转化而来。前者是一个多分类模型，而后者是一个二分类模型。\n",
    "\n",
    "softmax --> 标签用one-hot进行编码，logistic用0/1进行编码\n",
    "\n",
    "softmax函数，打分，概率值，\n",
    "\n",
    "logit == 打分，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow 中的一些概念\n",
    "\n",
    "tensor: 表示节点\n",
    "\n",
    "占位符：tensor,由用户传递给tf,用来存储样本数据和标签\n",
    "\n",
    "变量: tensor，指在整个计算过程中是可以改变的值\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Software\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# 使用tensorflow定义一个Softmax模型，实现MNIST数据集的分类\n",
    "\n",
    "# 创建占位符用来保存训练集数据\n",
    "X = tf.placeholder(tf.float32,[None,784]) # --> 指定了数据类型，指定了传入数据的shape\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "# 创建变量用来保存权值w 和偏置b\n",
    "W = tf.Variable(tf.zeros([784,10])) # --> 不需要指明数据类型，需要shape以及一个初始值\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# 建立输入与输出之间的关系\n",
    "# 输出为y_pre\n",
    "y_pred = tf.nn.softmax(tf.matmul(X,W)+b) # matmul --> 表示一个矩阵乘法，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义损失函数 loss，即交叉熵函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义交叉熵损失函数\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y*tf.log(y_pred)))\n",
    "\n",
    "# y = [0,1,0,0,0,0,0,0], y_pred = [a,b,c,d,e]对应于1的那一项y_pred应该接近于1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个优化求解器进行求解\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "# 0.01表示学习率 learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建会话，准备求解该模型了\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# 初始化所有变量，分配内存\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "会话表示节点进行计算的上下文\n",
    "\n",
    "在会话中初始化变量，在会话中保存变量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行1000步的梯度下降优化\n",
    "for _ in range(1000):\n",
    "    # 用minibatch\n",
    "    batch_x,batch_y = minist.train.next_batch(100)\n",
    "    sess.run(train_step,feed_dict={X:batch_x,y:batch_y}) # 使用feed_dict喂入数据\n",
    "\n",
    "# 占位符的值不会被保存，每一次都可以传入不同的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.arg_max(y,1),tf.arg_max(y_pred,1))\n",
    "# y_pred 已经计算 出来了，\n",
    "# y 是占位符还要等待着用户输入数据\n",
    "# 每一次运算都要通过sess.run()进行\n",
    "# tf.cast() 进行数据间的转换工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9024\n"
     ]
    }
   ],
   "source": [
    "# 获得最终模型的准确率\n",
    "print(sess.run(accuracy,feed_dict={X:minist.test.images,y:minist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **模型的预测准确率**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.2 两层卷积网络分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将图像还原为原来的shape\n",
    "X_image = tf.reshape(X,[-1,28,28,1]) # X --> 占位符\n",
    "\n",
    "# [N,W,H,D]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义四个函数，用来初始化权重，与偏置，卷积操作以及池化操作\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bia_variable(shape):\n",
    "    initial = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(X,W): # X表示输入的，W表示filter\n",
    "    return tf.nn.conv2d(X,W,strides=[1,1,1,1],padding='SAME')\n",
    "\n",
    "def max_pool_2x2(X):\n",
    "    return tf.nn.max_pool(X,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一层卷积\n",
    "W_conv1 = weight_variable([5,5,1,32]) # 5X5 表示大小，1表示channel，32表示filter的数量\n",
    "b_conv1 = bia_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(X_image,W_conv1)+b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二层卷积\n",
    "W_conv2 = weight_variable([5,5,32,64]) # 5X5 32 个通道， 64个filter\n",
    "b_conv2 = bia_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2)+b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全连接层\n",
    "W_fc1 = weight_variable([7*7*64,1024]) # 1024个neuron\n",
    "b_fcl = bia_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fcl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在该全连接层使用dropout技术\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将全连接层转换为最后的输入\n",
    "W_fc2 = weight_variable([1024,10])\n",
    "b_fc2 = bia_variable([10])\n",
    "y_conv = tf.matmul(h_fc1_drop,W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义交叉熵损失函数\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义测试的准确率\n",
    "correct_pred = tf.equal(tf.argmax(y_conv,1),tf.arg_max(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, train accuracy 0.04\n",
      "step 100, train accuracy 0.82\n",
      "step 200, train accuracy 0.86\n",
      "step 300, train accuracy 0.96\n",
      "step 400, train accuracy 0.92\n",
      "step 500, train accuracy 0.96\n",
      "step 600, train accuracy 0.92\n",
      "step 700, train accuracy 0.92\n",
      "step 800, train accuracy 0.92\n",
      "step 900, train accuracy 0.94\n",
      "step 1000, train accuracy 0.98\n",
      "step 1100, train accuracy 0.96\n",
      "step 1200, train accuracy 0.98\n",
      "step 1300, train accuracy 0.92\n",
      "step 1400, train accuracy 0.94\n",
      "step 1500, train accuracy 0.98\n",
      "step 1600, train accuracy 0.94\n",
      "step 1700, train accuracy 0.98\n",
      "step 1800, train accuracy 0.94\n",
      "step 1900, train accuracy 0.94\n",
      "step 2000, train accuracy 1\n",
      "step 2100, train accuracy 1\n",
      "step 2200, train accuracy 0.98\n",
      "step 2300, train accuracy 0.98\n",
      "step 2400, train accuracy 0.98\n",
      "step 2500, train accuracy 0.94\n",
      "step 2600, train accuracy 1\n",
      "step 2700, train accuracy 1\n",
      "step 2800, train accuracy 0.98\n",
      "step 2900, train accuracy 0.98\n",
      "step 3000, train accuracy 0.96\n",
      "step 3100, train accuracy 0.96\n",
      "step 3200, train accuracy 1\n",
      "step 3300, train accuracy 0.96\n",
      "step 3400, train accuracy 0.98\n",
      "step 3500, train accuracy 0.96\n",
      "step 3600, train accuracy 0.98\n",
      "step 3700, train accuracy 1\n",
      "step 3800, train accuracy 0.98\n",
      "step 3900, train accuracy 1\n",
      "step 4000, train accuracy 0.96\n",
      "step 4100, train accuracy 0.98\n",
      "step 4200, train accuracy 0.98\n",
      "step 4300, train accuracy 0.98\n",
      "step 4400, train accuracy 1\n",
      "step 4500, train accuracy 0.98\n",
      "step 4600, train accuracy 0.96\n",
      "step 4700, train accuracy 1\n",
      "step 4800, train accuracy 1\n",
      "step 4900, train accuracy 1\n",
      "step 5000, train accuracy 1\n",
      "step 5100, train accuracy 1\n",
      "step 5200, train accuracy 1\n",
      "step 5300, train accuracy 1\n",
      "step 5400, train accuracy 1\n",
      "step 5500, train accuracy 0.98\n",
      "step 5600, train accuracy 1\n",
      "step 5700, train accuracy 1\n",
      "step 5800, train accuracy 1\n",
      "step 5900, train accuracy 0.96\n",
      "step 6000, train accuracy 0.98\n",
      "step 6100, train accuracy 1\n",
      "step 6200, train accuracy 0.98\n",
      "step 6300, train accuracy 1\n",
      "step 6400, train accuracy 0.96\n",
      "step 6500, train accuracy 1\n",
      "step 6600, train accuracy 0.98\n",
      "step 6700, train accuracy 0.98\n",
      "step 6800, train accuracy 1\n",
      "step 6900, train accuracy 0.98\n",
      "step 7000, train accuracy 1\n",
      "step 7100, train accuracy 0.96\n",
      "step 7200, train accuracy 1\n",
      "step 7300, train accuracy 1\n",
      "step 7400, train accuracy 1\n",
      "step 7500, train accuracy 0.98\n",
      "step 7600, train accuracy 0.98\n",
      "step 7700, train accuracy 0.98\n",
      "step 7800, train accuracy 1\n",
      "step 7900, train accuracy 1\n",
      "step 8000, train accuracy 0.98\n",
      "step 8100, train accuracy 1\n",
      "step 8200, train accuracy 1\n",
      "step 8300, train accuracy 1\n",
      "step 8400, train accuracy 0.98\n",
      "step 8500, train accuracy 1\n",
      "step 8600, train accuracy 0.98\n",
      "step 8700, train accuracy 1\n",
      "step 8800, train accuracy 1\n",
      "step 8900, train accuracy 1\n",
      "step 9000, train accuracy 1\n",
      "step 9100, train accuracy 0.98\n",
      "step 9200, train accuracy 0.98\n",
      "step 9300, train accuracy 1\n",
      "step 9400, train accuracy 0.98\n",
      "step 9500, train accuracy 0.98\n",
      "step 9600, train accuracy 1\n",
      "step 9700, train accuracy 1\n",
      "step 9800, train accuracy 1\n",
      "step 9900, train accuracy 1\n",
      "step 10000, train accuracy 1\n",
      "step 10100, train accuracy 0.98\n",
      "step 10200, train accuracy 1\n",
      "step 10300, train accuracy 1\n",
      "step 10400, train accuracy 0.98\n",
      "step 10500, train accuracy 1\n",
      "step 10600, train accuracy 1\n",
      "step 10700, train accuracy 1\n",
      "step 10800, train accuracy 0.98\n",
      "step 10900, train accuracy 1\n",
      "step 11000, train accuracy 1\n",
      "step 11100, train accuracy 0.98\n",
      "step 11200, train accuracy 0.98\n",
      "step 11300, train accuracy 1\n",
      "step 11400, train accuracy 1\n",
      "step 11500, train accuracy 1\n",
      "step 11600, train accuracy 1\n",
      "step 11700, train accuracy 1\n",
      "step 11800, train accuracy 1\n",
      "step 11900, train accuracy 1\n",
      "step 12000, train accuracy 1\n",
      "step 12100, train accuracy 0.98\n",
      "step 12200, train accuracy 1\n",
      "step 12300, train accuracy 1\n",
      "step 12400, train accuracy 1\n",
      "step 12500, train accuracy 1\n",
      "step 12600, train accuracy 0.98\n",
      "step 12700, train accuracy 1\n",
      "step 12800, train accuracy 1\n",
      "step 12900, train accuracy 1\n",
      "step 13000, train accuracy 0.98\n",
      "step 13100, train accuracy 1\n",
      "step 13200, train accuracy 1\n",
      "step 13300, train accuracy 1\n",
      "step 13400, train accuracy 1\n",
      "step 13500, train accuracy 1\n",
      "step 13600, train accuracy 1\n",
      "step 13700, train accuracy 1\n",
      "step 13800, train accuracy 1\n",
      "step 13900, train accuracy 1\n",
      "step 14000, train accuracy 1\n",
      "step 14100, train accuracy 1\n",
      "step 14200, train accuracy 1\n",
      "step 14300, train accuracy 1\n",
      "step 14400, train accuracy 1\n",
      "step 14500, train accuracy 1\n",
      "step 14600, train accuracy 1\n",
      "step 14700, train accuracy 0.98\n",
      "step 14800, train accuracy 0.98\n",
      "step 14900, train accuracy 1\n",
      "step 15000, train accuracy 1\n",
      "step 15100, train accuracy 0.98\n",
      "step 15200, train accuracy 1\n",
      "step 15300, train accuracy 1\n",
      "step 15400, train accuracy 1\n",
      "step 15500, train accuracy 1\n",
      "step 15600, train accuracy 1\n",
      "step 15700, train accuracy 1\n",
      "step 15800, train accuracy 1\n",
      "step 15900, train accuracy 1\n",
      "step 16000, train accuracy 1\n",
      "step 16100, train accuracy 1\n",
      "step 16200, train accuracy 1\n",
      "step 16300, train accuracy 1\n",
      "step 16400, train accuracy 0.98\n",
      "step 16500, train accuracy 1\n",
      "step 16600, train accuracy 1\n",
      "step 16700, train accuracy 1\n",
      "step 16800, train accuracy 1\n",
      "step 16900, train accuracy 1\n",
      "step 17000, train accuracy 1\n",
      "step 17100, train accuracy 1\n",
      "step 17200, train accuracy 1\n",
      "step 17300, train accuracy 1\n",
      "step 17400, train accuracy 1\n",
      "step 17500, train accuracy 1\n",
      "step 17600, train accuracy 1\n",
      "step 17700, train accuracy 0.98\n",
      "step 17800, train accuracy 1\n",
      "step 17900, train accuracy 1\n",
      "step 18000, train accuracy 1\n",
      "step 18100, train accuracy 1\n",
      "step 18200, train accuracy 1\n",
      "step 18300, train accuracy 1\n",
      "step 18400, train accuracy 1\n",
      "step 18500, train accuracy 1\n",
      "step 18600, train accuracy 1\n",
      "step 18700, train accuracy 0.98\n",
      "step 18800, train accuracy 1\n",
      "step 18900, train accuracy 1\n",
      "step 19000, train accuracy 1\n",
      "step 19100, train accuracy 1\n",
      "step 19200, train accuracy 1\n",
      "step 19300, train accuracy 1\n",
      "step 19400, train accuracy 1\n",
      "step 19500, train accuracy 0.98\n",
      "step 19600, train accuracy 1\n",
      "step 19700, train accuracy 1\n",
      "step 19800, train accuracy 1\n",
      "step 19900, train accuracy 1\n"
     ]
    }
   ],
   "source": [
    "# 创建session\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(20000):\n",
    "    batch = minist.train.next_batch(50)\n",
    "    \n",
    "    # epoch\n",
    "    if i %100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={X:batch[0],y:batch[1],keep_prob:1.0})\n",
    "        print(\"step %d, train accuracy %g\"%(i,train_accuracy))\n",
    "    train_step.run(feed_dict={X:batch[0],y:batch[1],keep_prob:0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
